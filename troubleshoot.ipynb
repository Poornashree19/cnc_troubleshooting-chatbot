{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (2.6.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: transformers in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (4.48.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from transformers) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from transformers) (2.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from scikit-learn) (1.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from requests->transformers) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "%pip install torch transformers pandas scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (25.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from torchvision) (2.2.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (25.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "00\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File found! Loading dataset...\n",
      " Dataset loaded successfully!\n",
      "                              Issue  \\\n",
      "0  Machining start point is invalid   \n",
      "1    Cutting conditions are invalid   \n",
      "2         Finishing is not possible   \n",
      "3             Interference occurred   \n",
      "4          No machining cycle found   \n",
      "\n",
      "                                              Cause  \\\n",
      "0                     The machining area is invalid   \n",
      "1          Feedrate or other settings are incorrect   \n",
      "2             The conditions do not allow finishing   \n",
      "3  Tool path interferes with another machining area   \n",
      "4                  Only a figure block is specified   \n",
      "\n",
      "                                            Solution Unnamed: 3  \n",
      "0       Change the start point or modify the program        NaN  \n",
      "1  Modify the program with correct cutting condit...        NaN  \n",
      "2            Review and adjust the finishing program        NaN  \n",
      "3         Modify the tool path to avoid interference        NaN  \n",
      "4    Modify the program to include a machining cycle        NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "file_path = r\"C:\\Users\\poorn\\OneDrive\\Desktop\\cnc_chatbot_troubleshooting\\cnc_troubleshooting_dataset.csv\"\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    print(\"File found! Loading dataset...\")\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(\" Dataset loaded successfully!\")\n",
    "        print(df.head()) \n",
    "    except Exception as e:\n",
    "        print(f\" Error while reading the file: {e}\")\n",
    "else:\n",
    "    print(\" File not found! Please check the file path:\", file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"Question\": \"query\", \"Answer\": \"response\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File found! Loading dataset...\n",
      "Dataset loaded successfully!\n",
      "                              Issue  \\\n",
      "0  Machining start point is invalid   \n",
      "1    Cutting conditions are invalid   \n",
      "2         Finishing is not possible   \n",
      "3             Interference occurred   \n",
      "4          No machining cycle found   \n",
      "\n",
      "                                              Cause  \\\n",
      "0                     The machining area is invalid   \n",
      "1          Feedrate or other settings are incorrect   \n",
      "2             The conditions do not allow finishing   \n",
      "3  Tool path interferes with another machining area   \n",
      "4                  Only a figure block is specified   \n",
      "\n",
      "                                            Solution Unnamed: 3  \n",
      "0       Change the start point or modify the program        NaN  \n",
      "1  Modify the program with correct cutting condit...        NaN  \n",
      "2            Review and adjust the finishing program        NaN  \n",
      "3         Modify the tool path to avoid interference        NaN  \n",
      "4    Modify the program to include a machining cycle        NaN  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "['query', 'response']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14100\\777486896.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# Renaming columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"Question\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"query\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Answer\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"response\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m# Basic preprocessing: removing nulls and lowercasing text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"query\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"response\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"query\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"query\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"response\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"response\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\poorn\\OneDrive\\Desktop\\cnc_chatbot_troubleshooting\\cnc_env\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[0m\n\u001b[0;32m   6666\u001b[0m             \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6667\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6668\u001b[0m             \u001b[0mcheck\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6669\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6670\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6671\u001b[0m             \u001b[0magg_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6673\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mthresh\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_default\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ['query', 'response']"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"C:\\Users\\poorn\\OneDrive\\Desktop\\cnc_chatbot_troubleshooting\\cnc_troubleshooting_dataset.csv\"\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    print(\"File found! Loading dataset...\")\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(\"Dataset loaded successfully!\")\n",
    "        print(df.head())\n",
    "    except Exception as e:\n",
    "        print(f\"Error while reading the file: {e}\")\n",
    "else:\n",
    "    print(\"File not found! Please check the file path:\", file_path)\n",
    "\n",
    "# Renaming columns\n",
    "df.rename(columns={\"Question\": \"query\", \"Answer\": \"response\"}, inplace=True)\n",
    "\n",
    "# Basic preprocessing: removing nulls and lowercasing text\n",
    "df.dropna(subset=[\"query\", \"response\"], inplace=True)\n",
    "df[\"query\"] = df[\"query\"].str.lower()\n",
    "df[\"response\"] = df[\"response\"].str.lower()\n",
    "\n",
    "# Splitting the data into train and test sets\n",
    "X = df[\"query\"]\n",
    "y = df[\"response\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorizing the queries using TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Model: Logistic Regression for classification\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Making predictions and evaluating the model\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Example: making a prediction\n",
    "def predict_response(query):\n",
    "    query_tfidf = vectorizer.transform([query.lower()])\n",
    "    response = model.predict(query_tfidf)[0]\n",
    "    return response\n",
    "\n",
    "# Testing the prediction function\n",
    "sample_query = \"How do I fix a CNC machine error?\"\n",
    "predicted_response = predict_response(sample_query)\n",
    "print(f\"Query: {sample_query}\\nPredicted Response: {predicted_response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Issue', 'Cause', 'Solution', 'Unnamed: 3'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.strip() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File found! Loading dataset...\n",
      "Dataset loaded successfully!\n",
      "                              Issue  \\\n",
      "0  Machining start point is invalid   \n",
      "1    Cutting conditions are invalid   \n",
      "2         Finishing is not possible   \n",
      "3             Interference occurred   \n",
      "4          No machining cycle found   \n",
      "\n",
      "                                              Cause  \\\n",
      "0                     The machining area is invalid   \n",
      "1          Feedrate or other settings are incorrect   \n",
      "2             The conditions do not allow finishing   \n",
      "3  Tool path interferes with another machining area   \n",
      "4                  Only a figure block is specified   \n",
      "\n",
      "                                            Solution Unnamed: 3  \n",
      "0       Change the start point or modify the program        NaN  \n",
      "1  Modify the program with correct cutting condit...        NaN  \n",
      "2            Review and adjust the finishing program        NaN  \n",
      "3         Modify the tool path to avoid interference        NaN  \n",
      "4    Modify the program to include a machining cycle        NaN  \n",
      "Classification Report:\n",
      "                                                       precision    recall  f1-score   support\n",
      "\n",
      "         adjust program for normal cutting conditions       0.00      0.00      0.00         1\n",
      "                   check servo system and reduce load       0.00      0.00      0.00         1\n",
      "                  ensure the figure is a closed shape       0.00      0.00      0.00         0\n",
      "         modify program or check tool offset settings       0.00      0.00      0.00         1\n",
      "     modify the program or check tool offset settings       0.00      0.00      0.00         0\n",
      "modify the program to specify the correct return mode       0.00      0.00      0.00         1\n",
      "   modify the program with correct cutting conditions       0.00      0.00      0.00         0\n",
      "       modify the program with correct machining type       0.00      0.00      0.00         0\n",
      "           modify the tool path to avoid interference       1.00      1.00      1.00         1\n",
      "                specify an appropriate chamfer amount       0.00      0.00      0.00         1\n",
      "           specify an appropriate compensation number       0.00      0.00      0.00         1\n",
      "                  specify an appropriate depth of cut       0.00      0.00      0.00         2\n",
      "                    specify an appropriate dwell time       0.00      0.00      0.00         0\n",
      "       specify an appropriate feedrate in the program       1.00      1.00      1.00         1\n",
      "                 specify an appropriate overrun value       1.00      1.00      1.00         1\n",
      "\n",
      "                                             accuracy                           0.27        11\n",
      "                                            macro avg       0.20      0.20      0.20        11\n",
      "                                         weighted avg       0.27      0.27      0.27        11\n",
      "\n",
      "Query: How do I fix a CNC machine error?\n",
      "Predicted Response: perform real-time sensor-based diagnostics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\poorn\\OneDrive\\Desktop\\cnc_chatbot_troubleshooting\\cnc_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\poorn\\OneDrive\\Desktop\\cnc_chatbot_troubleshooting\\cnc_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\poorn\\OneDrive\\Desktop\\cnc_chatbot_troubleshooting\\cnc_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\poorn\\OneDrive\\Desktop\\cnc_chatbot_troubleshooting\\cnc_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\poorn\\OneDrive\\Desktop\\cnc_chatbot_troubleshooting\\cnc_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\poorn\\OneDrive\\Desktop\\cnc_chatbot_troubleshooting\\cnc_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "file_path = r\"C:\\Users\\poorn\\OneDrive\\Desktop\\cnc_chatbot_troubleshooting\\cnc_troubleshooting_dataset.csv\"\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    print(\"File found! Loading dataset...\")\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(\"Dataset loaded successfully!\")\n",
    "        print(df.head())\n",
    "    except Exception as e:\n",
    "        print(f\"Error while reading the file: {e}\")\n",
    "else:\n",
    "    print(\"File not found! Please check the file path:\", file_path)\n",
    "\n",
    "df.rename(columns={\"Issue\": \"query\", \"Solution\": \"response\"}, inplace=True)\n",
    "\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "df.dropna(subset=[\"query\", \"response\"], inplace=True)\n",
    "df[\"query\"] = df[\"query\"].str.lower()\n",
    "df[\"response\"] = df[\"response\"].str.lower()\n",
    "\n",
    "\n",
    "X = df[\"query\"]\n",
    "y = df[\"response\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "def predict_response(query):\n",
    "    query_tfidf = vectorizer.transform([query.lower()])\n",
    "    response = model.predict(query_tfidf)[0]\n",
    "    return response\n",
    "\n",
    "sample_query = \"How do I fix a CNC machine error?\"\n",
    "predicted_response = predict_response(sample_query)\n",
    "print(f\"Query: {sample_query}\\nPredicted Response: {predicted_response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (4.48.2)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from transformers) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from transformers) (2.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-19.0.0-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Using cached aiohttp-3.11.11-cp312-cp312-win_amd64.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets)\n",
      "  Downloading attrs-25.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Using cached frozenlist-1.5.0-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Using cached multidict-6.1.0-cp312-cp312-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets)\n",
      "  Using cached propcache-0.2.1-cp312-cp312-win_amd64.whl.metadata (9.5 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
      "  Using cached yarl-1.18.3-cp312-cp312-win_amd64.whl.metadata (71 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Using cached aiohttp-3.11.11-cp312-cp312-win_amd64.whl (437 kB)\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading pyarrow-19.0.0-cp312-cp312-win_amd64.whl (25.2 MB)\n",
      "   ---------------------------------------- 0.0/25.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/25.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/25.2 MB 1.1 MB/s eta 0:00:23\n",
      "   - -------------------------------------- 0.8/25.2 MB 1.2 MB/s eta 0:00:20\n",
      "   - -------------------------------------- 1.0/25.2 MB 1.3 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 1.6/25.2 MB 1.5 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 2.4/25.2 MB 1.9 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 2.6/25.2 MB 1.9 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 3.1/25.2 MB 1.9 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 3.7/25.2 MB 2.1 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 4.2/25.2 MB 2.2 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 4.2/25.2 MB 2.2 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 5.0/25.2 MB 2.0 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 5.5/25.2 MB 2.1 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 5.8/25.2 MB 2.1 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 6.3/25.2 MB 2.1 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 6.8/25.2 MB 2.1 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 7.3/25.2 MB 2.1 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 7.6/25.2 MB 2.1 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 8.1/25.2 MB 2.1 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 8.4/25.2 MB 2.0 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 8.7/25.2 MB 2.0 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 9.2/25.2 MB 2.0 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 9.4/25.2 MB 2.0 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 9.7/25.2 MB 1.9 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 10.0/25.2 MB 1.9 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 10.2/25.2 MB 1.9 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 10.5/25.2 MB 1.9 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 10.7/25.2 MB 1.8 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 10.7/25.2 MB 1.8 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 10.7/25.2 MB 1.8 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 11.0/25.2 MB 1.7 MB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 11.0/25.2 MB 1.7 MB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 11.0/25.2 MB 1.7 MB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 11.0/25.2 MB 1.7 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 11.5/25.2 MB 1.6 MB/s eta 0:00:09\n",
      "   ------------------- -------------------- 12.1/25.2 MB 1.6 MB/s eta 0:00:09\n",
      "   ------------------- -------------------- 12.6/25.2 MB 1.6 MB/s eta 0:00:08\n",
      "   -------------------- ------------------- 13.1/25.2 MB 1.6 MB/s eta 0:00:08\n",
      "   --------------------- ------------------ 13.6/25.2 MB 1.7 MB/s eta 0:00:08\n",
      "   ---------------------- ----------------- 13.9/25.2 MB 1.7 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 14.7/25.2 MB 1.7 MB/s eta 0:00:07\n",
      "   ------------------------ --------------- 15.2/25.2 MB 1.7 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 15.2/25.2 MB 1.7 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 15.7/25.2 MB 1.7 MB/s eta 0:00:06\n",
      "   -------------------------- ------------- 16.5/25.2 MB 1.7 MB/s eta 0:00:06\n",
      "   -------------------------- ------------- 16.8/25.2 MB 1.7 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 17.6/25.2 MB 1.8 MB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 17.8/25.2 MB 1.8 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 18.6/25.2 MB 1.8 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 19.4/25.2 MB 1.9 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 20.2/25.2 MB 1.9 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 20.7/25.2 MB 1.9 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 21.0/25.2 MB 1.9 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 21.8/25.2 MB 1.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 22.3/25.2 MB 1.9 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 22.8/25.2 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 23.1/25.2 MB 1.9 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 23.3/25.2 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.9/25.2 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.6/25.2 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.2/25.2 MB 2.0 MB/s eta 0:00:00\n",
      "Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl (30 kB)\n",
      "Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading attrs-25.1.0-py3-none-any.whl (63 kB)\n",
      "Using cached frozenlist-1.5.0-cp312-cp312-win_amd64.whl (51 kB)\n",
      "Using cached multidict-6.1.0-cp312-cp312-win_amd64.whl (28 kB)\n",
      "Using cached propcache-0.2.1-cp312-cp312-win_amd64.whl (44 kB)\n",
      "Using cached yarl-1.18.3-cp312-cp312-win_amd64.whl (90 kB)\n",
      "Installing collected packages: xxhash, pyarrow, propcache, multidict, fsspec, frozenlist, dill, attrs, aiohappyeyeballs, yarl, multiprocess, aiosignal, aiohttp, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.2.0\n",
      "    Uninstalling fsspec-2025.2.0:\n",
      "      Successfully uninstalled fsspec-2025.2.0\n",
      "Successfully installed aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiosignal-1.3.2 attrs-25.1.0 datasets-3.2.0 dill-0.3.8 frozenlist-1.5.0 fsspec-2024.9.0 multidict-6.1.0 multiprocess-0.70.16 propcache-0.2.1 pyarrow-19.0.0 xxhash-3.5.0 yarl-1.18.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers datasets torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from accelerate) (2.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from accelerate) (24.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from accelerate) (6.1.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from accelerate) (2.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from accelerate) (0.28.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from accelerate) (0.5.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from torch>=2.0.0->accelerate) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers[torch] in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (4.48.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from transformers[torch]) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from transformers[torch]) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from transformers[torch]) (2.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from transformers[torch]) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from transformers[torch]) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from transformers[torch]) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from transformers[torch]) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from transformers[torch]) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from transformers[torch]) (4.67.1)\n",
      "Requirement already satisfied: torch>=2.0 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from transformers[torch]) (2.6.0)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from accelerate>=0.26.0->transformers[torch]) (6.1.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers[torch]) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers[torch]) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from torch>=2.0->transformers[torch]) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from torch>=2.0->transformers[torch]) (3.1.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from torch>=2.0->transformers[torch]) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from torch>=2.0->transformers[torch]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from sympy==1.13.1->torch>=2.0->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from requests->transformers[torch]) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from requests->transformers[torch]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from requests->transformers[torch]) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from requests->transformers[torch]) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\poorn\\onedrive\\desktop\\cnc_chatbot_troubleshooting\\cnc_env\\lib\\site-packages (from jinja2->torch>=2.0->transformers[torch]) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pip install --upgrade accelerate\n",
    "%pip install transformers[torch]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File found! Loading dataset...\n",
      "Dataset loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 42/42 [00:00<00:00, 3862.75 examples/s]\n",
      "Map: 100%|| 11/11 [00:00<00:00, 1226.27 examples/s]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\poorn\\OneDrive\\Desktop\\cnc_chatbot_troubleshooting\\cnc_env\\Lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The model did not return a loss from the inputs, only the following keys: logits. For reference, the inputs it received are input_ids,token_type_ids,attention_mask.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 92\u001b[0m\n\u001b[0;32m     83\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     84\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,                         \n\u001b[0;32m     85\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,                   \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     88\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,     \n\u001b[0;32m     89\u001b[0m )\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[1;32m---> 92\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# Save the trained model and tokenizer\u001b[39;00m\n\u001b[0;32m     95\u001b[0m model\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./cnc_troubleshooting_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\poorn\\OneDrive\\Desktop\\cnc_chatbot_troubleshooting\\cnc_env\\Lib\\site-packages\\transformers\\trainer.py:2171\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2169\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2172\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\poorn\\OneDrive\\Desktop\\cnc_chatbot_troubleshooting\\cnc_env\\Lib\\site-packages\\transformers\\trainer.py:2531\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2524\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2525\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m   2526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2527\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[0;32m   2528\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[0;32m   2529\u001b[0m )\n\u001b[0;32m   2530\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m-> 2531\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2534\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2535\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2536\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2537\u001b[0m ):\n\u001b[0;32m   2538\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2539\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mc:\\Users\\poorn\\OneDrive\\Desktop\\cnc_chatbot_troubleshooting\\cnc_env\\Lib\\site-packages\\transformers\\trainer.py:3675\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[0;32m   3672\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   3674\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 3675\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3677\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[0;32m   3678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   3679\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3680\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   3681\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\poorn\\OneDrive\\Desktop\\cnc_chatbot_troubleshooting\\cnc_env\\Lib\\site-packages\\transformers\\trainer.py:3752\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[0;32m   3750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3751\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m outputs:\n\u001b[1;32m-> 3752\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3753\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model did not return a loss from the inputs, only the following keys: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3754\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(outputs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. For reference, the inputs it received are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(inputs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3755\u001b[0m         )\n\u001b[0;32m   3756\u001b[0m     \u001b[38;5;66;03m# We don't use .loss here since the model may return tuples instead of ModelOutput.\u001b[39;00m\n\u001b[0;32m   3757\u001b[0m     loss \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: The model did not return a loss from the inputs, only the following keys: logits. For reference, the inputs it received are input_ids,token_type_ids,attention_mask."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Path to your dataset\n",
    "file_path = r\"C:\\Users\\poorn\\OneDrive\\Desktop\\cnc_chatbot_troubleshooting\\cnc_troubleshooting_dataset.csv\"\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(file_path):\n",
    "    print(\"File found! Loading dataset...\")\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(\"Dataset loaded successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error while reading the file: {e}\")\n",
    "else:\n",
    "    print(\"File not found! Please check the file path:\", file_path)\n",
    "\n",
    "# Data preprocessing\n",
    "df.rename(columns={\"Issue\": \"query\", \"Solution\": \"response\"}, inplace=True)\n",
    "df.columns = df.columns.str.strip()\n",
    "df.dropna(subset=[\"query\", \"response\"], inplace=True)\n",
    "df[\"query\"] = df[\"query\"].str.lower()\n",
    "df[\"response\"] = df[\"response\"].str.lower()\n",
    "\n",
    "# Use LabelEncoder to convert responses into numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"response_label\"] = label_encoder.fit_transform(df[\"response\"])\n",
    "\n",
    "# Split dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"query\"], df[\"response_label\"], test_size=0.2, random_state=42)\n",
    "\n",
    "train_data = pd.DataFrame({\"query\": X_train, \"response_label\": y_train})\n",
    "test_data = pd.DataFrame({\"query\": X_test, \"response_label\": y_test})\n",
    "\n",
    "# Convert the pandas dataframe to Hugging Face dataset format\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "test_dataset = Dataset.from_pandas(test_data)\n",
    "\n",
    "# Initialize the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['query'], truncation=True, padding=True, max_length=512)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Load the pre-trained BERT model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_))\n",
    "\n",
    "# Compute metrics for evaluation\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    preds = torch.argmax(predictions, axis=1)\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          \n",
    "    evaluation_strategy=\"epoch\",     \n",
    "    learning_rate=2e-5,              \n",
    "    per_device_train_batch_size=8,   \n",
    "    per_device_eval_batch_size=16,   \n",
    "    num_train_epochs=3,             \n",
    "    weight_decay=0.01,               \n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,                         \n",
    "    args=training_args,                   \n",
    "    train_dataset=train_dataset,        \n",
    "    eval_dataset=test_dataset,          \n",
    "    compute_metrics=compute_metrics,     \n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n",
    "\n",
    "# Save the trained model and tokenizer\n",
    "model.save_pretrained(\"./cnc_troubleshooting_model\")\n",
    "tokenizer.save_pretrained(\"./cnc_troubleshooting_model\")\n",
    "\n",
    "# Evaluate the model\n",
    "trainer.evaluate()\n",
    "\n",
    "# Function to predict the response\n",
    "def predict_response(query):\n",
    "    inputs = tokenizer(query, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    outputs = model(**inputs)\n",
    "    prediction = torch.argmax(outputs.logits, axis=1).item()  # Get the prediction index\n",
    "    predicted_response = label_encoder.inverse_transform([prediction])  # Convert label back to response text\n",
    "    return predicted_response[0]\n",
    "\n",
    "# Taking input from the user for prediction\n",
    "sample_query = input(\"Enter your CNC troubleshooting query: \").lower()\n",
    "predicted_response = predict_response(sample_query)\n",
    "print(f\"Query: {sample_query}\\nPredicted Response: {predicted_response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File found! Loading dataset...\n",
      "Dataset loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 42/42 [00:00<00:00, 3009.44 examples/s]\n",
      "Map: 100%|| 11/11 [00:00<00:00, 1573.47 examples/s]\n",
      "Map: 100%|| 42/42 [00:00<00:00, 6992.73 examples/s]\n",
      "Map: 100%|| 11/11 [00:00<00:00, 1577.78 examples/s]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\poorn\\OneDrive\\Desktop\\cnc_chatbot_troubleshooting\\cnc_env\\Lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 7/18 00:07 < 00:15, 0.69 it/s, Epoch 1/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "argmax(): argument 'input' (position 1) must be Tensor, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 98\u001b[0m\n\u001b[0;32m     89\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     90\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,                         \n\u001b[0;32m     91\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,                   \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     94\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,     \n\u001b[0;32m     95\u001b[0m )\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[1;32m---> 98\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# Save the trained model and tokenizer\u001b[39;00m\n\u001b[0;32m    101\u001b[0m model\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./cnc_troubleshooting_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\poorn\\OneDrive\\Desktop\\cnc_chatbot_troubleshooting\\cnc_env\\Lib\\site-packages\\transformers\\trainer.py:2171\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2169\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2172\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\poorn\\OneDrive\\Desktop\\cnc_chatbot_troubleshooting\\cnc_env\\Lib\\site-packages\\transformers\\trainer.py:2625\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2622\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   2624\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m-> 2625\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DebugOption\u001b[38;5;241m.\u001b[39mTPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[0;32m   2628\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_xla_available():\n\u001b[0;32m   2629\u001b[0m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\poorn\\OneDrive\\Desktop\\cnc_chatbot_troubleshooting\\cnc_env\\Lib\\site-packages\\transformers\\trainer.py:3071\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[1;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time)\u001b[0m\n\u001b[0;32m   3069\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3070\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate:\n\u001b[1;32m-> 3071\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3072\u001b[0m     is_new_best_metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_determine_best_metric(metrics\u001b[38;5;241m=\u001b[39mmetrics, trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[0;32m   3074\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave_strategy \u001b[38;5;241m==\u001b[39m SaveStrategy\u001b[38;5;241m.\u001b[39mBEST:\n",
      "File \u001b[1;32mc:\\Users\\poorn\\OneDrive\\Desktop\\cnc_chatbot_troubleshooting\\cnc_env\\Lib\\site-packages\\transformers\\trainer.py:3025\u001b[0m, in \u001b[0;36mTrainer._evaluate\u001b[1;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[0;32m   3024\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, ignore_keys_for_eval, skip_scheduler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m-> 3025\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3026\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[0;32m   3028\u001b[0m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\poorn\\OneDrive\\Desktop\\cnc_chatbot_troubleshooting\\cnc_env\\Lib\\site-packages\\transformers\\trainer.py:4073\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[1;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   4070\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   4072\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[1;32m-> 4073\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4074\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4075\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4076\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[0;32m   4077\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[0;32m   4078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   4079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4081\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4083\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[0;32m   4084\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[1;32mc:\\Users\\poorn\\OneDrive\\Desktop\\cnc_chatbot_troubleshooting\\cnc_env\\Lib\\site-packages\\transformers\\trainer.py:4362\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[1;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   4360\u001b[0m     eval_set_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlosses\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m all_losses \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args\u001b[38;5;241m.\u001b[39minclude_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   4361\u001b[0m     eval_set_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m all_inputs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args\u001b[38;5;241m.\u001b[39minclude_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 4362\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4363\u001b[0m \u001b[43m        \u001b[49m\u001b[43mEvalPrediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meval_set_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4364\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4365\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4366\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m {}\n",
      "Cell \u001b[1;32mIn[20], line 67\u001b[0m, in \u001b[0;36mcompute_metrics\u001b[1;34m(p)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_metrics\u001b[39m(p):\n\u001b[0;32m     66\u001b[0m     predictions, labels \u001b[38;5;241m=\u001b[39m p\n\u001b[1;32m---> 67\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(labels, preds)\n\u001b[0;32m     69\u001b[0m     precision, recall, f1, _ \u001b[38;5;241m=\u001b[39m precision_recall_fscore_support(labels, preds, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: argmax(): argument 'input' (position 1) must be Tensor, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Path to your dataset\n",
    "file_path = r\"C:\\Users\\poorn\\OneDrive\\Desktop\\cnc_chatbot_troubleshooting\\cnc_troubleshooting_dataset.csv\"\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(file_path):\n",
    "    print(\"File found! Loading dataset...\")\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(\"Dataset loaded successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error while reading the file: {e}\")\n",
    "else:\n",
    "    print(\"File not found! Please check the file path:\", file_path)\n",
    "\n",
    "# Data preprocessing\n",
    "df.rename(columns={\"Issue\": \"query\", \"Solution\": \"response\"}, inplace=True)\n",
    "df.columns = df.columns.str.strip()\n",
    "df.dropna(subset=[\"query\", \"response\"], inplace=True)\n",
    "df[\"query\"] = df[\"query\"].str.lower()\n",
    "df[\"response\"] = df[\"response\"].str.lower()\n",
    "\n",
    "# Use LabelEncoder to convert responses into numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"response_label\"] = label_encoder.fit_transform(df[\"response\"])\n",
    "\n",
    "# Split dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"query\"], df[\"response_label\"], test_size=0.2, random_state=42)\n",
    "\n",
    "train_data = pd.DataFrame({\"query\": X_train, \"response_label\": y_train})\n",
    "test_data = pd.DataFrame({\"query\": X_test, \"response_label\": y_test})\n",
    "\n",
    "# Convert the pandas dataframe to Hugging Face dataset format\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "test_dataset = Dataset.from_pandas(test_data)\n",
    "\n",
    "# Initialize the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    # Tokenize both 'query' and 'response_label' (we pass 'response_label' as the label)\n",
    "    return tokenizer(examples['query'], truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# Apply tokenization to both train and test datasets\n",
    "train_dataset = train_dataset.map(lambda x: tokenize_function(x), batched=True)\n",
    "test_dataset = test_dataset.map(lambda x: tokenize_function(x), batched=True)\n",
    "\n",
    "# Adding the label column for classification\n",
    "train_dataset = train_dataset.map(lambda x: {'labels': x['response_label']}, batched=True)\n",
    "test_dataset = test_dataset.map(lambda x: {'labels': x['response_label']}, batched=True)\n",
    "\n",
    "# Load the pre-trained BERT model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_))\n",
    "\n",
    "# Compute metrics for evaluation\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    preds = torch.argmax(predictions, axis=1)\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          \n",
    "    evaluation_strategy=\"epoch\",     \n",
    "    learning_rate=2e-5,              \n",
    "    per_device_train_batch_size=8,   \n",
    "    per_device_eval_batch_size=16,   \n",
    "    num_train_epochs=3,             \n",
    "    weight_decay=0.01,               \n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,                         \n",
    "    args=training_args,                   \n",
    "    train_dataset=train_dataset,        \n",
    "    eval_dataset=test_dataset,          \n",
    "    compute_metrics=compute_metrics,     \n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n",
    "\n",
    "# Save the trained model and tokenizer\n",
    "model.save_pretrained(\"./cnc_troubleshooting_model\")\n",
    "tokenizer.save_pretrained(\"./cnc_troubleshooting_model\")\n",
    "\n",
    "# Evaluate the model\n",
    "trainer.evaluate()\n",
    "\n",
    "# Function to predict the response\n",
    "def predict_response(query):\n",
    "    inputs = tokenizer(query, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    outputs = model(**inputs)\n",
    "    prediction = torch.argmax(outputs.logits, axis=1).item()  # Get the prediction index\n",
    "    predicted_response = label_encoder.inverse_transform([prediction])  # Convert label back to response text\n",
    "    return predicted_response[0]\n",
    "\n",
    "# Taking input from the user for prediction\n",
    "sample_query = input(\"Enter your CNC troubleshooting query: \").lower()\n",
    "predicted_response = predict_response(sample_query)\n",
    "print(f\"Query: {sample_query}\\nPredicted Response: {predicted_response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File found! Loading dataset...\n",
      "Dataset loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 42/42 [00:00<00:00, 3510.44 examples/s]\n",
      "Map: 100%|| 11/11 [00:00<00:00, 1378.10 examples/s]\n",
      "Map: 100%|| 42/42 [00:00<00:00, 7717.21 examples/s]\n",
      "Map: 100%|| 11/11 [00:00<00:00, 1589.68 examples/s]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\poorn\\OneDrive\\Desktop\\cnc_chatbot_troubleshooting\\cnc_env\\Lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:19, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.899039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.914707</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.922032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\poorn\\OneDrive\\Desktop\\cnc_chatbot_troubleshooting\\cnc_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\poorn\\OneDrive\\Desktop\\cnc_chatbot_troubleshooting\\cnc_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\poorn\\OneDrive\\Desktop\\cnc_chatbot_troubleshooting\\cnc_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\poorn\\OneDrive\\Desktop\\cnc_chatbot_troubleshooting\\cnc_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\poorn\\OneDrive\\Desktop\\cnc_chatbot_troubleshooting\\cnc_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\poorn\\OneDrive\\Desktop\\cnc_chatbot_troubleshooting\\cnc_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\poorn\\OneDrive\\Desktop\\cnc_chatbot_troubleshooting\\cnc_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\poorn\\OneDrive\\Desktop\\cnc_chatbot_troubleshooting\\cnc_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: cutting conditions are invalid\n",
      "Predicted Response: modify the program with correct groove width\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "file_path = r\"C:\\Users\\poorn\\OneDrive\\Desktop\\cnc_chatbot_troubleshooting\\cnc_troubleshooting_dataset.csv\"\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    print(\"File found! Loading dataset...\")\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(\"Dataset loaded successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error while reading the file: {e}\")\n",
    "else:\n",
    "    print(\"File not found! Please check the file path:\", file_path)\n",
    "\n",
    "\n",
    "df.rename(columns={\"Issue\": \"query\", \"Solution\": \"response\"}, inplace=True)\n",
    "df.columns = df.columns.str.strip()\n",
    "df.dropna(subset=[\"query\", \"response\"], inplace=True)\n",
    "df[\"query\"] = df[\"query\"].str.lower()\n",
    "df[\"response\"] = df[\"response\"].str.lower()\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"response_label\"] = label_encoder.fit_transform(df[\"response\"])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"query\"], df[\"response_label\"], test_size=0.2, random_state=42)\n",
    "\n",
    "train_data = pd.DataFrame({\"query\": X_train, \"response_label\": y_train})\n",
    "test_data = pd.DataFrame({\"query\": X_test, \"response_label\": y_test})\n",
    "\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "test_dataset = Dataset.from_pandas(test_data)\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "\n",
    "    return tokenizer(examples['query'], truncation=True, padding=True, max_length=512)\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(lambda x: tokenize_function(x), batched=True)\n",
    "test_dataset = test_dataset.map(lambda x: tokenize_function(x), batched=True)\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(lambda x: {'labels': x['response_label']}, batched=True)\n",
    "test_dataset = test_dataset.map(lambda x: {'labels': x['response_label']}, batched=True)\n",
    "\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_))\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "   \n",
    "    predictions = torch.tensor(predictions)\n",
    "   \n",
    "    preds = torch.argmax(predictions, axis=1)\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          \n",
    "    evaluation_strategy=\"epoch\",     \n",
    "    learning_rate=2e-5,              \n",
    "    per_device_train_batch_size=8,   \n",
    "    per_device_eval_batch_size=16,   \n",
    "    num_train_epochs=3,             \n",
    "    weight_decay=0.01,               \n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         \n",
    "    args=training_args,                   \n",
    "    train_dataset=train_dataset,        \n",
    "    eval_dataset=test_dataset,          \n",
    "    compute_metrics=compute_metrics,     \n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "model.save_pretrained(\"./cnc_troubleshooting_model\")\n",
    "tokenizer.save_pretrained(\"./cnc_troubleshooting_model\")\n",
    "\n",
    "\n",
    "trainer.evaluate()\n",
    "\n",
    "\n",
    "def predict_response(query):\n",
    "    inputs = tokenizer(query, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    outputs = model(**inputs)\n",
    "    prediction = torch.argmax(outputs.logits, axis=1).item()  \n",
    "    predicted_response = label_encoder.inverse_transform([prediction]) \n",
    "    return predicted_response[0]\n",
    "\n",
    "\n",
    "sample_query = input(\"Enter your CNC troubleshooting query: \").lower()\n",
    "predicted_response = predict_response(sample_query)\n",
    "print(f\"Query: {sample_query}\\nPredicted Response: {predicted_response}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
